{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b1579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 22)\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "import joblib\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from Scripts.dbConnection import cnxn, Data_Inserting_Into_DB\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "class VAR:\n",
    "    db_mkanalyzer = 'mkanalyzer'\n",
    "    db_mkintervalmaster = 'mkintervalmaster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7df6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketAnalyzer:\n",
    "    def __init__(self, kwargs):\n",
    "        self.cnxn = cnxn(VAR.db_mkintervalmaster)\n",
    "        self.Date = kwargs.get('Date')\n",
    "        self.symbol = kwargs.get('tickerName')\n",
    "        self.start_date = kwargs.get('start_date')\n",
    "        self.end_date = kwargs.get('end_date')\n",
    "        self.market_data = None\n",
    "\n",
    "    def get_market_data(self):\n",
    "        query = f\"select * from [{self.symbol}] where Datetime <= '{self.end_date}' \"\n",
    "        self.market_data= pd.read_sql(query, self.cnxn)\n",
    "        return self.market_data\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_rsi(data, window):\n",
    "        delta = data.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def identify_market_phases(self):\n",
    "        self.market_data['SMA_20'] = self.market_data['Close'].rolling(window=20).mean()\n",
    "        self.market_data['SMA_50'] = self.market_data['Close'].rolling(window=50).mean()\n",
    "        self.market_data['RSI'] = self.calculate_rsi(self.market_data['Close'], 14)\n",
    "        self.market_data['Accumulation'] = np.where((self.market_data['Close'] > self.market_data['SMA_20']) & \n",
    "                                                    (self.market_data['Close'] > self.market_data['SMA_50']), 1, 0)\n",
    "        self.market_data['Advancing'] = np.where((self.market_data['SMA_20'] > self.market_data['SMA_50']) & \n",
    "                                                 (self.market_data['Close'] > self.market_data['SMA_20']), 1, 0)\n",
    "        self.market_data['Distribution'] = np.where((self.market_data['Close'] < self.market_data['SMA_20']) & \n",
    "                                                    (self.market_data['Close'] < self.market_data['SMA_50']), 1, 0)\n",
    "        self.market_data['Declining'] = np.where((self.market_data['SMA_20'] > self.market_data['SMA_50']) & \n",
    "                                                 (self.market_data['Close'] < self.market_data['SMA_20']), 1, 0)\n",
    "        return self.market_data\n",
    "\n",
    "    def analyze(self):\n",
    "        self.get_market_data()\n",
    "        market_data_with_phases = self.identify_market_phases()\n",
    "        return market_data_with_phases\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20f8e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictor:\n",
    "    def __init__(self, kwargs, test_size=0.3, random_state=42, lr=0.001, num_epochs=1000):\n",
    "        self.db_mkanalyzer = 'mkanalyzer'\n",
    "        self.tickerName = kwargs.get('tickerName')\n",
    "        self.inputDate = kwargs.get('Datetime')\n",
    "        self.successCount = kwargs.get('counts')\n",
    "#         self.features = ['diffEntry', 'diffExit', 'diffHigh', 'LS_Day']\n",
    "        self.features = ['diffEntry', 'diffExit', 'diffHigh', 'LS_Day', 'pMomentum', 'nMomentum', 'buySignal', 'sellSignal', 'holdingSignal']\n",
    "        self.target = 'TmPLShifted'\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.dfPhases = None\n",
    "         \n",
    "    def fetchData(self):\n",
    "        query = f'''\n",
    "        WITH cte AS (\n",
    "            SELECT CAST(predDatetime AS DATE) AS Datetime, \n",
    "                   tickerName, \n",
    "                   Entry2 AS ActualEntry, \n",
    "                   Exit2 AS ActualExit, \n",
    "                   [High] AS ActualHigh,\n",
    "                   predTmEntry2 AS PredEntry, \n",
    "                   predTmExit2 AS PredExit, \n",
    "                   [Close],\n",
    "                   CASE \n",
    "                       WHEN (Entry2 <= predTmEntry2 AND (Exit2 >= predTmExit2 OR predTmEntry2 < [Close])) \n",
    "                       THEN 1 \n",
    "                       ELSE 0 \n",
    "                   END AS TmPL,\n",
    "                   CASE \n",
    "                       WHEN (Entry2 <= predTmEntry2) OR (predTmEntry2 >= [Close])\n",
    "                       THEN 1 \n",
    "                       ELSE 0 \n",
    "                   END AS gotEntry,\n",
    "                   CASE \n",
    "                       WHEN (Entry2 <= predTmEntry2 AND (Exit2 >= predTmExit2 OR predTmEntry2 < [Close])) \n",
    "                       THEN 0\n",
    "                       WHEN (Entry2 <= predTmEntry2 AND predTmEntry2 >= [Close]) OR (predTmEntry2 >= [Close])\n",
    "                       THEN 1 \n",
    "                       ELSE 0 \n",
    "                   END AS gotLoss,\n",
    "                   CASE \n",
    "                       WHEN [High] >= predTmExit2 \n",
    "                       THEN 1\n",
    "                       ELSE 0 \n",
    "                   END AS gotSell,\n",
    "                   CASE \n",
    "                       WHEN (Entry2 <= predTmEntry2 AND Exit2 >= predTmExit2) \n",
    "                       THEN ROUND(((predTmExit2 - predTmEntry2) / predTmExit2) * 100, 2)\n",
    "                       ELSE ROUND((([Close] - predTmEntry2) / [Close]) * 100, 2)\n",
    "                   END AS ActualProfit, \n",
    "                   EtEx2Profit AS PredProfit\n",
    "            FROM simulationPrediction \n",
    "            WHERE tickerName = '{self.tickerName}' \n",
    "              AND predDatetime <= '{self.inputDate}'\n",
    "        ),\n",
    "        LSDAY AS (\n",
    "            SELECT CAST(Datetime AS DATE) AS Datetime,\n",
    "                   ROUND(CASE\n",
    "                       WHEN MAX([Close]) = 0 OR SUM(Volume) = 0 THEN NULL\n",
    "                       ELSE ((MAX([High]) - MIN([Low])) / MAX([Close])) * LOG(SUM(Volume) / COUNT(DISTINCT CONVERT(date, Datetime)))\n",
    "                   END, 2) AS LS_Day\n",
    "            FROM mkdaymaster.dbo.[{self.tickerName}]\n",
    "            GROUP BY Datetime, [High], [Low], [Close], [Volume]\n",
    "        )\n",
    "        SELECT c.*,  \n",
    "               ROUND((ActualEntry - PredEntry) / PredEntry * 100, 2) AS diffEntry,\n",
    "               ROUND((ActualExit - PredExit) / PredExit * 100, 2) AS diffExit,\n",
    "               ROUND((ActualHigh - PredExit) / PredExit * 100, 2) AS diffHigh,\n",
    "               LAG(CASE WHEN gotSell = 1 THEN ROUND(([Close] - PredExit) / PredExit * 100, 2) ELSE 0 END, 1) \n",
    "                   OVER (ORDER BY c.Datetime DESC) AS diffClose,\n",
    "               LAG(gotSell, 1) OVER (ORDER BY c.Datetime DESC) AS gotSellShifted,\n",
    "               LAG(TmPL, 1) OVER (ORDER BY c.Datetime DESC) AS TmPLShifted,\n",
    "               LAG(gotEntry, 1) OVER (ORDER BY c.Datetime DESC) AS gotEntryShifted,\n",
    "               LAG(gotLoss, 1) OVER (ORDER BY c.Datetime DESC) AS gotLossShifted,\n",
    "               LAG(ActualProfit, 1) OVER (ORDER BY c.Datetime DESC) AS ActualProfitShifted,\n",
    "               ld.LS_Day,\n",
    "               LAG(\n",
    "                   CASE \n",
    "                       WHEN (TmPL = 1 AND ActualProfit = PredProfit) THEN 'ETEX' \n",
    "                       WHEN (TmPL = 1 AND ActualProfit != PredProfit) THEN 'ETCL' \n",
    "                       WHEN (gotEntry = 1 AND gotLoss = 1) THEN 'ETLS'\n",
    "                       ELSE 'NOET' \n",
    "                   END, 1\n",
    "               ) OVER (ORDER BY c.Datetime DESC) AS TmPredShifted\n",
    "        FROM cte c\n",
    "        LEFT JOIN LSDAY ld ON ld.Datetime = c.Datetime\n",
    "        ORDER BY c.Datetime DESC;\n",
    "        '''\n",
    "        return pd.read_sql(query, cnxn(self.db_mkanalyzer))\n",
    "    \n",
    "    def getMarketPhases(self):\n",
    "        tickerDetails = {\n",
    "            'tickerName': self.tickerName, \n",
    "            'end_date': (pd.to_datetime(self.inputDate) + pd.Timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "        }\n",
    "        dfPhases = MarketAnalyzer(tickerDetails).analyze()\n",
    "        dfPhases['tickerName'] = self.tickerName\n",
    "        dfPhases = dfPhases.sort_values(by='Datetime').reset_index(drop=True)\n",
    "        dfPhases['Date'] = pd.to_datetime(dfPhases['Datetime']).dt.date\n",
    "        dfPhases = dfPhases.groupby('Date').agg(\n",
    "            tickerName=('tickerName', lambda x: x.unique()[0]),\n",
    "            Close315=('Open', lambda x: x.iloc[-3] if len(x) >= 3 else x.iloc[0]),\n",
    "            Accumulation=('Accumulation', 'sum'),\n",
    "            Advancing=('Advancing', 'sum'),\n",
    "            Distribution=('Distribution', 'sum'),\n",
    "            Declining=('Declining', 'sum'),\n",
    "            RSI=('RSI', lambda x: {\n",
    "                'buySignal': len([item for item in x if item < 30]),\n",
    "                'sellSignal': len([item for item in x if item > 70]),\n",
    "                'holdingSignal': len([item for item in x if item >= 30 and item <= 70])\n",
    "            })\n",
    "        ).reset_index()\n",
    "        dfPhases['pMomentum'] = (((dfPhases['Accumulation']+dfPhases['Advancing'])/(dfPhases['Accumulation']+dfPhases['Advancing']+dfPhases['Distribution']+dfPhases['Declining']))*100).round(2)\n",
    "        dfPhases['nMomentum'] = (((dfPhases['Distribution']+dfPhases['Declining'])/(dfPhases['Accumulation']+dfPhases['Advancing']+dfPhases['Distribution']+dfPhases['Declining']))*100).round(2)\n",
    "        dfPhases = pd.concat([dfPhases.drop(columns=['RSI']), dfPhases['RSI'].apply(pd.Series)], axis=1)\n",
    "        self.dfPhases = dfPhases\n",
    "\n",
    "    def preprocess_data(self, df, target):\n",
    "        first_row = df.iloc[0]\n",
    "        df_remaining = df.iloc[1:]\n",
    "        df_remaining = df_remaining.dropna()\n",
    "        class SimpleNN(nn.Module):\n",
    "            def __init__(self, input_size, hidden_size, output_size):\n",
    "                super(SimpleNN, self).__init__()\n",
    "                self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "                self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = torch.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "    \n",
    "        X_remaining = df_remaining[self.features]\n",
    "        y_remaining = df_remaining[target]\n",
    "        \n",
    "        smote = SMOTE(random_state=self.random_state)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_remaining, y_remaining)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_resampled)\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y_resampled)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=self.test_size, random_state=self.random_state)\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "        \n",
    "        batch_size = 64\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        input_size = X_train.shape[1]\n",
    "        hidden_size = 64\n",
    "        output_size = len(label_encoder.classes_)\n",
    "        model = SimpleNN(input_size, hidden_size, output_size)\n",
    "        \n",
    "        class_counts = torch.bincount(y_train_tensor)\n",
    "        total_samples = len(y_train_tensor)\n",
    "        class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "        class_weights = class_weights.to(torch.float32)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.lr)\n",
    "        \n",
    "        epochs = self.num_epochs\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * batch_X.size(0)\n",
    "            epoch_loss = running_loss / len(train_dataset)\n",
    "            # print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "            # print(f'Accuracy on Test Data: {accuracy * 100:.2f}%')\n",
    "        \n",
    "        df_remaining_scaled = scaler.transform(df_remaining[self.features])\n",
    "        X_full_tensor = torch.tensor(df_remaining_scaled, dtype=torch.float32)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_full_tensor)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        df_remaining['TmPredPL'] = label_encoder.inverse_transform(predictions.numpy())\n",
    "        \n",
    "        first_row_scaled = scaler.transform(first_row[self.features].values.reshape(1, -1))\n",
    "        first_row_tensor = torch.tensor(first_row_scaled, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            first_row_output = model(first_row_tensor)\n",
    "            _, first_row_prediction = torch.max(first_row_output, 1)\n",
    "        first_row['TmPredPL'] = label_encoder.inverse_transform(first_row_prediction.numpy())[0]\n",
    "        \n",
    "        df_updated = pd.concat([pd.DataFrame([first_row]), df_remaining], ignore_index=True)\n",
    "        modelAccuracy = round(accuracy * 100, 2)\n",
    "        epochLoss = round(epoch_loss * 100, 2)\n",
    "        phasesColumns = [item for item in self.dfPhases.columns if item not in ['Date', 'tickerName']]\n",
    "        dfResult = pd.DataFrame([first_row])\n",
    "        dfResult['successCount'] = self.successCount\n",
    "        dfResult['modelAccuracy'] = modelAccuracy\n",
    "        dfResult['epochLoss'] = epochLoss\n",
    "        dfResult = dfResult[['Datetime', 'tickerName', 'TmPredPL', 'ActualEntry', 'ActualExit', 'ActualHigh', 'PredEntry', 'PredExit', 'ActualProfit', 'PredProfit', 'diffEntry', 'diffExit', 'diffHigh', 'LS_Day', *phasesColumns, 'successCount', 'modelAccuracy', 'epochLoss']]\n",
    "        dfResult['TmPredPL'] = dfResult['TmPredPL'].astype(int)\n",
    "        return dfResult, modelAccuracy, epochLoss\n",
    "\n",
    "    def run(self):\n",
    "        if not self.dfPhases:\n",
    "            self.getMarketPhases()\n",
    "        df = self.fetchData()\n",
    "        df = df.merge(self.dfPhases.drop(columns=['tickerName']), how='left', left_on='Datetime', right_on='Date')\n",
    "        resultDct = {}\n",
    "        targetList = ['TmPLShifted', 'gotLoss']\n",
    "        for target in targetList:\n",
    "            best_dfResult, best_accuracy, best_epochLoss = None, 0, 100\n",
    "            lstResult = []\n",
    "            for i in range(5):\n",
    "                dfResult, accuracy, epochLoss = self.preprocess_data(df, target)\n",
    "                lstResult.append({target: dfResult[['TmPredPL', 'successCount', 'modelAccuracy', 'epochLoss']]})\n",
    "                if epochLoss < best_epochLoss:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_epochLoss = epochLoss\n",
    "                    best_dfResult = dfResult\n",
    "            resultDct[target] = [best_dfResult, lstResult]\n",
    "        return resultDct\n",
    "    \n",
    "def topAccurateTickers(top=None, filterDate=None): \n",
    "    query = f'''\n",
    "    SELECT sp.tickerName, COUNT(sp.Datetime) AS counts, '{filterDate}' as Datetime, ETEXProfit\n",
    "    FROM simulationPrediction AS sp\n",
    "    LEFT JOIN (SELECT tickerName, EtEx2Profit as ETEXProfit FROM simulationPrediction WHERE Datetime='{filterDate}') p ON p.tickerName=sp.tickerName\n",
    "    WHERE Entry2 <= predTmEntry2 AND Exit2 >= predTmExit2\n",
    "    AND CAST(Datetime AS DATE) >= CAST(DATEADD(MONTH, -1, '{filterDate}') AS DATE)\n",
    "    AND CAST(Datetime AS DATE) < CAST('{filterDate}' AS DATE)\n",
    "    GROUP BY sp.tickerName, ETEXProfit\n",
    "    ORDER BY counts DESC, ETEXProfit DESC\n",
    "    '''\n",
    "    df = pd.read_sql(query, cnxn(VAR.db_mkanalyzer)).iloc[:top]\n",
    "    tickerList = df.to_dict('records')\n",
    "    result = []\n",
    "    for kwargs in tqdm(tickerList, desc='Tm Prediction'):\n",
    "        obj = StockPredictor(kwargs)\n",
    "        resultDct = obj.run()\n",
    "        result.append(resultDct)\n",
    "    if result:\n",
    "        return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def jobMarketPredictor():\n",
    "    query = '''\n",
    "    SELECT DISTINCT(Datetime) FROM simulationPrediction\n",
    "    WHERE Datetime >= DATEADD(MONTH, -1, (SELECT MAX(Datetime) FROM simulationPrediction))\n",
    "    ORDER BY Datetime ASC\n",
    "    '''\n",
    "    dateList = pd.read_sql(query, cnxn(VAR.db_mkanalyzer))['Datetime'].dt.date.astype(str).tolist()[-5:-4]\n",
    "    lst = []\n",
    "    for date in dateList:\n",
    "        print(f'{date:#^75}')\n",
    "        result = topAccurateTickers(top=1, filterDate=date)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8fa566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################2024-08-23#################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tm Prediction: 100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.81s/it]\n"
     ]
    }
   ],
   "source": [
    "result = jobMarketPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7efb4f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'TmPLShifted': [     Datetime tickerName  TmPredPL  ActualEntry  ActualExit  ActualHigh  \\\n",
      "0  2024-08-23        MOL         1       100.45      104.72      104.73   \n",
      "\n",
      "   PredEntry  PredExit  ActualProfit  PredProfit  diffEntry  diffExit  \\\n",
      "0     100.87    104.89          1.79        3.83      -0.42     -0.16   \n",
      "\n",
      "   diffHigh  LS_Day  Close315  Accumulation  Advancing  Distribution  \\\n",
      "0     -0.15    0.65    102.75            51         41             1   \n",
      "\n",
      "   Declining  pMomentum  nMomentum  buySignal  sellSignal  holdingSignal  \\\n",
      "0         21      80.70      19.30          9          11             55   \n",
      "\n",
      "   successCount  modelAccuracy  epochLoss  \n",
      "0             8          77.92      11.85  , [{'TmPLShifted':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         1             8          76.62      14.80}, {'TmPLShifted':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         1             8          77.92      14.21}, {'TmPLShifted':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         1             8          77.92      11.85}, {'TmPLShifted':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         1             8          79.22      12.74}, {'TmPLShifted':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         1             8          77.92      13.55}]], 'gotLoss': [     Datetime tickerName  TmPredPL  ActualEntry  ActualExit  ActualHigh  \\\n",
      "0  2024-08-23        MOL         0       100.45      104.72      104.73   \n",
      "\n",
      "   PredEntry  PredExit  ActualProfit  PredProfit  diffEntry  diffExit  \\\n",
      "0     100.87    104.89          1.79        3.83      -0.42     -0.16   \n",
      "\n",
      "   diffHigh  LS_Day  Close315  Accumulation  Advancing  Distribution  \\\n",
      "0     -0.15    0.65    102.75            51         41             1   \n",
      "\n",
      "   Declining  pMomentum  nMomentum  buySignal  sellSignal  holdingSignal  \\\n",
      "0         21      80.70      19.30          9          11             55   \n",
      "\n",
      "   successCount  modelAccuracy  epochLoss  \n",
      "0             8          85.19       3.27  , [{'gotLoss':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         0             8          87.04       3.94}, {'gotLoss':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         0             8          85.19       3.53}, {'gotLoss':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         0             8          85.19       3.94}, {'gotLoss':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         0             8          85.19       3.27}, {'gotLoss':    TmPredPL  successCount  modelAccuracy  epochLoss\n",
      "0         0             8          85.19       3.37}]]}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0430b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPhases['Bullish_Divergence'] = np.nan\n",
    "# dfPhases['Bearish_Divergence'] = np.nan\n",
    "# dfPhases['Buy_Signal'] = np.nan\n",
    "# dfPhases['Sell_Signal'] = np.nan\n",
    "# for i in range(1, len(dfPhases)):\n",
    "#     if dfPhases['Close'].iloc[i] < dfPhases['Close'].iloc[i-1] and dfPhases['RSI'].iloc[i] > dfPhases['RSI'].iloc[i-1]:\n",
    "#         dfPhases.loc[i, 'Bullish_Divergence'] = True\n",
    "#     if dfPhases['Close'].iloc[i] > dfPhases['Close'].iloc[i-1] and dfPhases['RSI'].iloc[i] < dfPhases['RSI'].iloc[i-1]:\n",
    "#         dfPhases.loc[i, 'Bearish_Divergence'] = True\n",
    "#     if dfPhases['RSI'].iloc[i-1] < 30 and dfPhases['RSI'].iloc[i] > 30:\n",
    "#         dfPhases.loc[i, 'Buy_Signal'] = True\n",
    "#     if dfPhases['RSI'].iloc[i-1] > 70 and dfPhases['RSI'].iloc[i] < 70:\n",
    "#         dfPhases.loc[i, 'Sell_Signal'] = True\n",
    "# bullish_divergences = dfPhases[dfPhases['Bullish_Divergence'].notna()].groupby('Date') ['Bullish_Divergence'].count().reset_index()\n",
    "# bearish_divergences = dfPhases[dfPhases['Bearish_Divergence'].notna()].groupby('Date') ['Bearish_Divergence'].count().reset_index()\n",
    "# buy_signals = dfPhases[dfPhases['Buy_Signal'].notna()].groupby('Date') ['Buy_Signal'].count().reset_index()\n",
    "# sell_signals = dfPhases[dfPhases['Sell_Signal'].notna()].groupby('Date') ['Sell_Signal'].count().reset_index()\n",
    "\n",
    "# # Output the signals\n",
    "# print(\"Bullish Divergences:\")\n",
    "# print(bullish_divergences)\n",
    "\n",
    "# print(\"\\nBearish Divergences:\")\n",
    "# print(bearish_divergences)\n",
    "\n",
    "# print(\"\\nBuy Signals:\")\n",
    "# print(buy_signals)\n",
    "\n",
    "# print(\"\\nSell Signals:\")\n",
    "# print(sell_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d38255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
